<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2024-12-21">

<title>Paper in Progress: Variance in AI Perceptions of Risk – Andreas Varotsis</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" integrity="sha384-ZvpUoO/+PpLXR1lu4jmpXWu80pZlYUAfxl5NsBMWOEPSjUn/6Z/hRTt8+pR6L4N2" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../favicon.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-707d8167ce6003fca903bfe2be84ab7f.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-cd884f2855776405ca61470c593c983e.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="dark">
<script src="../../site_libs/quarto-contrib/open-social-comments-1.0.0/social-comments.js"></script>
<link href="../../site_libs/quarto-contrib/fontawesome6-1.2.0/all.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-1.2.0/latex-fontsize.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=GG-378MDZNVX4"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'GG-378MDZNVX4', { 'anonymize_ip': true});
</script>
<style>html{ scroll-behavior: smooth; }</style>
<script src="https://cdn.jsdelivr.net/npm/requirejs@2.3.6/require.min.js" integrity="sha384-c9c+LnTbwQ3aujuU7ULEPVvgLs+Fn6fJUvIGTsuu1ZcCf11fiEubah0ttpca4ntM sha384-6V1/AdqZRWk1KAlWbKBlGhN7VG4iE/yAZcO6NZPMF8od0vukrvr0tg4qY6NSrItx" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/dompurify/2.4.1/purify.min.js" integrity="sha512-uHOKtSfJWScGmyyFr2O2+efpDx2nhwHU2v7MVeptzZoiC7bdF6Ny/CmZhN2AwIK1oCFiVQQ5DA/L9FSzyPNu6Q==" crossorigin="anonymous"></script><script type="text/javascript">
document.addEventListener('DOMContentLoaded', function() {
  var div = document.getElementById('quarto-content');
  if(div) {
    div.innerHTML += `<social-comments bluesky-post="https://bsky.app/profile/andreasthinks.me/post/3lf3dqtmyik2x"></social-comments>`;
  }
});
</script>
<script type="text/javascript">
var mastodonHost = "fosstodon.org";
var mastodonUser = "AndreasThinks";
var mastodonTootId = "113781980851850508";
</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Paper in Progress: Variance in AI Perceptions of Risk – Andreas Varotsis">
<meta property="og:description" content="Personal website for Andreas Varotsis">
<meta property="og:image" content="https://andreasthinks.me/posts/copbot_analysis/analysis_files/figure-html/fig-model-comparison-arena-output-1.png">
<meta property="og:site_name" content="Andreas Varotsis">
<meta property="og:image:height" content="532">
<meta property="og:image:width" content="1362">
<meta name="twitter:title" content="Paper in Progress: Variance in AI Perceptions of Risk – Andreas Varotsis">
<meta name="twitter:description" content="Personal website for Andreas Varotsis">
<meta name="twitter:image" content="https://andreasthinks.me/posts/copbot_analysis/analysis_files/figure-html/fig-model-comparison-arena-output-1.png">
<meta name="twitter:image-height" content="532">
<meta name="twitter:image-width" content="1362">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed fullcontent quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Andreas Varotsis</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../recent_work.html"> 
<span class="menu-text">Talks &amp; Publications</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../slides/index.html"> 
<span class="menu-text">Teaching</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://fosstodon.org/@AndreasThinks" rel="me"> 
<span class="menu-text"><i class="fa-brands fa-mastodon fa-xl" aria-label="mastodon"></i></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://bsky.app/profile/andreasthinks.me"> 
<span class="menu-text"><i class="fa-brands fa-bluesky fa-xl" aria-label="bluesky"></i></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://twitter.com/AndreasThinks"> 
<span class="menu-text"><i class="fa-brands fa-twitter fa-xl" aria-label="twitter"></i></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/AndreasThinks"> 
<span class="menu-text"><i class="fa-brands fa-github fa-xl" aria-label="github"></i></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://www.linkedin.com/in/avarotsis/"> 
<span class="menu-text"><i class="fa-brands fa-linkedin fa-xl" aria-label="linkedin"></i></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="mailto:andreas.varotsis@gmail.com"> 
<span class="menu-text"><i class="fa-solid fa-envelope fa-xl" aria-label="envelope"></i></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../index.xml"> 
<span class="menu-text"><i class="fa-solid fa-rss fa-xl" aria-label="rss"></i></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Paper in Progress: Variance in AI Perceptions of Risk</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li></ul></div></div>
                                <div class="quarto-categories">
                <div class="quarto-category">ai</div>
                <div class="quarto-category">policing</div>
                <div class="quarto-category">data-science</div>
                <div class="quarto-category">work-in-progress</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">December 21, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">





<div class="callout callout-style-default callout-note callout-titled" title="Paper in Progress">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Paper in Progress
</div>
</div>
<div class="callout-body-container callout-body">
<p>This is a research paper in progress: it’s unfinished, messy, and maybe nonsensical, but feedback is always very welcome.</p>
<p>This paper is now <a href="https://www.crimrxiv.com/pub/ngqxdnav">available as a pre-print</a>.</p>
</div>
</div>
<div id="cell-2" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">'ignore'</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="cell-3" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_coefficients_vertical_legend(group_name, group_df, color_map):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> group_df.empty:</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"No data available for group </span><span class="sc">{</span>group_name<span class="sc">}</span><span class="ss">. Skipping plot."</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">None</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    factors <span class="op">=</span> group_df[<span class="st">'new_name'</span>].dropna().unique()</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    x_positions <span class="op">=</span> np.arange(<span class="bu">len</span>(factors))</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    models <span class="op">=</span> group_df[<span class="st">'model'</span>].unique()</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    bar_width <span class="op">=</span> <span class="fl">0.8</span> <span class="op">/</span> <span class="bu">len</span>(models)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, model <span class="kw">in</span> <span class="bu">enumerate</span>(models):</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        model_data <span class="op">=</span> group_df[group_df[<span class="st">'model'</span>] <span class="op">==</span> model]</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>        aligned_data <span class="op">=</span> model_data.set_index(<span class="st">'new_name'</span>).reindex(factors).reset_index()</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>        positions <span class="op">=</span> x_positions <span class="op">+</span> i <span class="op">*</span> bar_width</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>        coeffs <span class="op">=</span> aligned_data[<span class="st">'Coef.'</span>]</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>        ci_low <span class="op">=</span> aligned_data[<span class="st">'ci_low'</span>]</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>        ci_high <span class="op">=</span> aligned_data[<span class="st">'ci_high'</span>]</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>        bar_style <span class="op">=</span> {<span class="st">"color"</span>: <span class="st">'dimgray'</span>, <span class="st">"hatch"</span>: <span class="st">'//'</span>, <span class="st">"alpha"</span>: <span class="fl">0.8</span>, <span class="st">"edgecolor"</span>: <span class="st">'black'</span>} <span class="cf">if</span> model <span class="op">==</span> <span class="st">"human"</span> <span class="cf">else</span> {<span class="st">"color"</span>: color_map.get(model, <span class="st">'blue'</span>), <span class="st">"alpha"</span>: <span class="fl">0.8</span>, <span class="st">"edgecolor"</span>: <span class="st">'black'</span>}</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>        error_color <span class="op">=</span> <span class="st">'black'</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>        plt.bar(positions, coeffs, bar_width, label<span class="op">=</span>model, <span class="op">**</span>bar_style)</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>        plt.errorbar(positions, coeffs, yerr<span class="op">=</span>[coeffs <span class="op">-</span> ci_low, ci_high <span class="op">-</span> coeffs], fmt<span class="op">=</span><span class="st">'none'</span>,</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>                     ecolor<span class="op">=</span>error_color, capsize<span class="op">=</span><span class="dv">3</span>, alpha<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>    plt.xticks(x_positions <span class="op">+</span> bar_width <span class="op">*</span> (<span class="bu">len</span>(models) <span class="op">-</span> <span class="dv">1</span>) <span class="op">/</span> <span class="dv">2</span>, factors, rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">'right'</span>)</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Regression Coefficients'</span>)</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>    plt.axhline(<span class="dv">0</span>, color<span class="op">=</span><span class="st">'black'</span>, linewidth<span class="op">=</span><span class="fl">0.8</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>    plt.legend(title<span class="op">=</span><span class="st">"Model"</span>, loc<span class="op">=</span><span class="st">'center left'</span>, bbox_to_anchor<span class="op">=</span>(<span class="fl">1.02</span>, <span class="fl">0.5</span>), ncol<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> fig</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> main(coefficients_path, new_names_path):</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>    coefficients <span class="op">=</span> pd.read_csv(coefficients_path)</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>    new_names <span class="op">=</span> pd.read_csv(new_names_path)</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>    coefficients <span class="op">=</span> coefficients.merge(new_names, left_on<span class="op">=</span><span class="st">'Unnamed: 0'</span>, right_on<span class="op">=</span><span class="st">'Original_name'</span>, how<span class="op">=</span><span class="st">'left'</span>)</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>    coefficients.rename(columns<span class="op">=</span>{<span class="st">'[0.025'</span>: <span class="st">'ci_low'</span>, <span class="st">'0.975]'</span>: <span class="st">'ci_high'</span>}, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>    coefficients[<span class="st">'significant'</span>] <span class="op">=</span> coefficients[<span class="st">'P&gt;|t|'</span>] <span class="op">&lt;</span> <span class="fl">0.05</span></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>    missing_name_mapping <span class="op">=</span> {</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>        <span class="st">"C(age, Treatment(reference=25))[T.5]"</span>: <span class="st">"Age 5"</span>,</span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>        <span class="st">"C(age, Treatment(reference=25))[T.10]"</span>: <span class="st">"Age 10"</span>,</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>        <span class="st">"C(age, Treatment(reference=25))[T.14]"</span>: <span class="st">"Age 14"</span>,</span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>        <span class="st">"C(age, Treatment(reference=25))[T.16]"</span>: <span class="st">"Age 16"</span>,</span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>        <span class="st">"C(age, Treatment(reference=25))[T.20]"</span>: <span class="st">"Age 20"</span>,</span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>        <span class="st">"C(age, Treatment(reference=25))[T.50]"</span>: <span class="st">"Age 50"</span>,</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a>        <span class="st">"C(age, Treatment(reference=25))[T.80]"</span>: <span class="st">"Age 80"</span>,</span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a>        <span class="st">"C(hours_missing, Treatment(reference=8))[T.10]"</span>: <span class="st">"Hours Missing 10"</span>,</span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a>        <span class="st">"C(hours_missing, Treatment(reference=8))[T.14]"</span>: <span class="st">"Hours Missing 14"</span>,</span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a>        <span class="st">"C(hours_missing, Treatment(reference=8))[T.18]"</span>: <span class="st">"Hours Missing 18"</span>,</span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a>        <span class="st">"C(ethnicity, Treatment(reference='White'))[T.Asian]"</span>: <span class="st">"Ethnicity: Asian"</span>,</span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a>        <span class="st">"C(ethnicity, Treatment(reference='White'))[T.Black]"</span>: <span class="st">"Ethnicity: Black"</span>,</span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>        <span class="st">"C(ethnicity, Treatment(reference='White'))[T.mixed race]"</span>: <span class="st">"Ethnicity: Mixed Race"</span></span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a>    coefficients[<span class="st">'new_name'</span>] <span class="op">=</span> coefficients[<span class="st">'new_name'</span>].fillna(</span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a>        coefficients[<span class="st">'Original_name'</span>].<span class="bu">map</span>(missing_name_mapping)</span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a>    grouped_coefficients <span class="op">=</span> coefficients.groupby(<span class="st">'Group'</span>)</span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a>    unique_models <span class="op">=</span> coefficients[<span class="st">'model'</span>].unique()</span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a>    color_map <span class="op">=</span> {model: plt.cm.tab10(i <span class="op">%</span> <span class="dv">10</span>) <span class="cf">for</span> i, model <span class="kw">in</span> <span class="bu">enumerate</span>(unique_models)}</span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a>    plots_dict <span class="op">=</span> {}</span>
<span id="cb2-66"><a href="#cb2-66" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> group_name, group_df <span class="kw">in</span> grouped_coefficients:</span>
<span id="cb2-67"><a href="#cb2-67" aria-hidden="true" tabindex="-1"></a>        plot <span class="op">=</span> plot_coefficients_vertical_legend(group_name, group_df, color_map)</span>
<span id="cb2-68"><a href="#cb2-68" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> plot:</span>
<span id="cb2-69"><a href="#cb2-69" aria-hidden="true" tabindex="-1"></a>            plots_dict[group_name] <span class="op">=</span> plot</span>
<span id="cb2-70"><a href="#cb2-70" aria-hidden="true" tabindex="-1"></a>            plt.close(plot)  <span class="co"># Close the figure to free memory</span></span>
<span id="cb2-71"><a href="#cb2-71" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb2-72"><a href="#cb2-72" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> plots_dict</span>
<span id="cb2-73"><a href="#cb2-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-74"><a href="#cb2-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-75"><a href="#cb2-75" aria-hidden="true" tabindex="-1"></a>coefficients_path <span class="op">=</span> <span class="st">"data/copbot_coefficients.csv"</span>  <span class="co"># Replace with your file path</span></span>
<span id="cb2-76"><a href="#cb2-76" aria-hidden="true" tabindex="-1"></a>new_names_path <span class="op">=</span> <span class="st">"data/copbot_new_names.csv"</span>    </span>
<span id="cb2-77"><a href="#cb2-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-78"><a href="#cb2-78" aria-hidden="true" tabindex="-1"></a>coefficient_plots <span class="op">=</span> main(coefficients_path, new_names_path)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<section id="abstract" class="level1">
<h1>Abstract</h1>
<p>The increasing adoption of Large Language Models (LLMs) in various domains raises questions about their application in policing and criminal justice, particularly regarding their ability to accurately assess risk and threat. This study examines how LLMs perceive and evaluate risk in missing person cases compared to human decision-makers. Using a purpose-built website, we collected over 600 risk assessments from human participants and compared these with assessments from seven different LLM models on randomly generated missing person scenarios. Through regression analysis, we found that while high-performing models like GPT-4o and Llama-3.1-70b generally aligned with human risk perceptions, showing mean absolute errors below 0.6 on a 4-point scale, they exhibited concerning biases, particularly regarding race. Unlike human assessors who showed no significant racial bias, all models demonstrated some form of racial bias in their risk assessments. Models also varied significantly in their evaluation of other risk factors, such as time missing and criminal history. Our findings suggest that while LLMs show promise for risk assessment applications, their deployment in policing contexts requires careful auditing for consistency and bias, particularly when dealing with protected characteristics.</p>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Since the public release of ChatGPT in 2022, there has been an explosion of interest in the application of Large Language Models (LLMsa) to a range of fields, including crime and policing. There is growing evidence that in some contexts, generative language models can aid human decision makers to make faster, more accurate decision, with one notable study examining the productivity of call centre handlers finding real productivity gains across their workforce (<span class="citation" data-cites="brynjolfssonGenerativeAIWork2023">Brynjolfsson, Li, and Raymond (<a href="#ref-brynjolfssonGenerativeAIWork2023" role="doc-biblioref">2023</a>)</span>). In the face of growing demand, reduced budgets, and pressure from central government, UK policing has started trying to seize these opportunities… and the market is responding with a number of “of the shelf” products designed specifically for law enforcement.</p>
<p>Perhaps the most recognisable of these tool is DraftOne, which brings together body-worn video footage and the OpenAI GPT-4o model to augment the process of writing statements: where once a police officer would have written a long, detailed statement from video records or from memory, now a generative AI model will create a “skeleton” report, containing the critical facts from the video, and leave the officer to “complete the blanks” and finalise the report. Axon claims officers “spend spend up to 40% of their time writing” reports, and that DraftOne could “cut that time in half”<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. While researchers in the UK couldn’t replicate those benefits (<span class="citation" data-cites="adamsNoMansHand2024">Adams et al. (<a href="#ref-adamsNoMansHand2024" role="doc-biblioref">2024</a>)</span>), they do find a range of other improvements, including completeness and cohesiveness. And while DraftOne may have been one of the earliest tools to involve generative AI in police decision making, it certainly won’t be the last, with other suppliers already touting it’s potentially transformative benefits<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> that go far beyond report writing: generative AI could help automate a vast range of tasks in the criminal justice system, from helping identify critical evidence, to translating witness testimony, or even providing audio-visual description of trials.</p>
<p>but how does changing one word matter? Surely it’s factual, and if a huamn is oin hte loop, then the decision can’t really change… can it?</p>
<p>Indeed, there is growing evidence that LLM enabled tools can, in the right context, provide real productivity benefits - roduce meaningful productivity benefits in certain contexts, though the evidence in policing remains poor.</p>
<p>There are however, specific challenges within these domains. Language Models reflect the text they are trained on, and as such, are subject to bias - while the concerns around algorithmic bias in policing are already broadly recognised, broad application of language models could aggravate these concerns, in ways that may be opaque or undetected.</p>
<p>In addition, policing and crime often deal with accurate individual perceptions of threat and risk: for example, a witness statement may ask the individual to recall how they felt at a specific time, and the perceived lack of safety may impact the existence of a crime, or the severity of sentencing. There is little to no research as to how accurately language models reflect human perceptions of threat and risk, or how this may interact with inbuilt biases around, for example, ethnicity or age.</p>
<p>To examine the presence of bias in individuals, one approach that has become frequently used in policing is <strong>vignette studies</strong>: asking individuals to consider simulated scenarios, and assess what an appropriate outcome may be (for example, whether an arrest or search would be justified.) In this paper, we apply a similar approach to language models, to answer our research question.</p>
<p>For ease of analysis and to ensure our findings are broadly applicable, we focus on the perception of risk around missing people reported to police in the England &amp; Wales. How these case are responded to and assessed is heavily regulated according to the College of Policing Approved Professional Practice, and as such is subject a well understood risk assessment: when a missing person is first reported, the reporting officer will conduct an initial assessment of risk, from “high risk” (where the risk of serious harm is very likely) to “very low risk”, where there is a very low risk of harm to either the subject or the public.</p>
<p>Using an online website designed for this research, we collected over 600 ratings from individuals, and then compared this to ratings from language models. By varying the circumstances of the missing person, this has allowed us to examine and measure perceptions of threat, risk, and bias in a range of language models.</p>
</section>
<section id="literature-review" class="level1">
<h1>Literature Review</h1>
<p>While there is limited evidence around the productivity benefits of LLMs in policing, we know they can be effective tools to improve productivity in some contexts: <span class="citation" data-cites="brynjolfssonGenerativeAIWork2023">Brynjolfsson, Li, and Raymond (<a href="#ref-brynjolfssonGenerativeAIWork2023" role="doc-biblioref">2023</a>)</span> found that for customer service agents, access to an LLM enabled tool “increases productivity, as measured by issues resolved per hour, by 14% on average, including a 34% improvement for novice and low-skilled workers but with minimal impact on experienced and highly skilled workers.”</p>
<p>The research that does exist suggests these may not translate to policing: <span class="citation" data-cites="adamsNoMansHand2024">Adams et al. (<a href="#ref-adamsNoMansHand2024" role="doc-biblioref">2024</a>)</span> conducted a robust, pre-registered randomised control trial for the DraftOne tool, and find that officers using the tool are no faster than those without it (though they do see improvements in report quality, for instance improved spelling and coherence). It suggests that the lack of productivity benefits may be down to existing use of template documents. As this only covers a single tool in a single operational context, further research is likely required to understand the mechanism.</p>
<p>Beyond productivity benefits, some researchers have examined how LLMs be specifically risk in the domains of crime and justice. <span class="citation" data-cites="fergusonGenerativeSuspicionRisks2024">Ferguson (<a href="#ref-fergusonGenerativeSuspicionRisks2024" role="doc-biblioref">2024</a>)</span> examines this from a legal perspective, noting that generative AI might “infect a foundational building block of the criminal justice system.” <span class="citation" data-cites="chanConversationalAIPowered2024">Chan et al. (<a href="#ref-chanConversationalAIPowered2024" role="doc-biblioref">2024</a>)</span> examine these concerns empirically in relation to witness statements, and find that LLM chatbots can unexpectedly create “false memories”, encouraging witnesses to recall events that have not truly occured. Similarly, <span class="citation" data-cites="hobsonArtificialFairnessTrust2023">Hobson et al. (<a href="#ref-hobsonArtificialFairnessTrust2023" role="doc-biblioref">2023</a>)</span> examined whether algorithmic decisions might be perceived as less “just” than human decisions, and does find this to be the case.</p>
</section>
<section id="data-and-method" class="level1">
<h1>Data and Method</h1>
<p>To collect our data, a public website was set up at <a href="https://copbot.online/">https://copbot.online/</a>, which was shared amongst a range of online police communities (eg, police reddit, twitter, and others). The website provides information about assessing risk from the College of Policing APP, collects a small number of personal details (such as their rough location, and whether or not they are a police officer or staff), and then walks them through conducting a risk assessment on a missing person scenario.</p>
<p>The scenario is randomly generated for each visitor, by varying a small number of key variables for the missing person:</p>
<ul>
<li>Their sex (male or female)</li>
<li>Their age (5,10,14,16,20,25,50,80)</li>
<li>What time they are reported missing / how long they have been missing (‘eight PM’, ‘ten PM’, ‘two AM’, ‘6 AM’)</li>
<li>Ethnicity (‘White’, ‘mixed race’, ‘Asian’, ‘Black’)</li>
<li>Whether the episode is out of character, whether they are a regular missing person, or if they are involved in crime (“they are known to have been involved in crime, and their disappearance is not out of character”, “they are being reported by family members, who are concerned as this has never happened before”, “The informant is not worried, as he says this has happened before and they always come home safe.”)</li>
</ul>
<p>The variables are then combined into a generate scenario, as in the example below:</p>
<p><strong>It is eight PM, and you are receiving a report of a missing person. They are a 50 year old, Asian male, who has gone missing from their home in London. They were last seen around midday. The informant is not worried, as he says this has happened before and they always come home safe.</strong></p>
<p>The individual is then asked to complete a risk assessment, according to the College of Policing principles, scoring the case on a sliding scale between “very low risk” and “high risk”. For measurement purposes, this scale is scored between 0 and 4, with 0.1 intervals.</p>
<p>The same scenario is then put to 2 distinct LLM models, each of which is asked to submit results on 20 occasions (to allow us to study variance in their decision making). Each response is then stored for further analysis, along with the original scenario.</p>
<p>Once the website had been created, we circulated the address through a range of policing online communities and social media, including Reddit and Twitter - as such, this is largely convenience sampling. Between July 2024 and December 2024, we collected around 610 results.</p>
<section id="models" class="level2">
<h2 class="anchored" data-anchor-id="models">Models</h2>
<p>For ease of analysis, we used <a href="https://www.litellm.ai/">LiteLLM</a> to query a range of different LLM models using the same approach. we focus on models from OpenAI, as well as a range of “open source” or other permission models, provided via <a href="https://groq.com/">Groq</a>, an online platform for serving language models.</p>
<p>To ensure the models returned measurable responses, we used “Structured Output” (we force the model to return entries in a numberical format). Not every model is compatible with this approach, and as such we only use a small number of models (this also allows us to reduce our costs).</p>
<ul>
<li>OpenAI Models
<ul>
<li>GPT-3.5
<ul>
<li>Summary: Released in March 2022, GPT-3.5 is a large language model with 175 billion parameters, and was a basis for ChatGPT, known for its improved ability to follow instructions compared to previous versions.</li>
</ul></li>
<li>GPT-4o
<ul>
<li>Summary: Released in May 2024, GPT-4o is one of OpenAI’s current flagship models, featuring improved performance in text, vision, and audio tasks compared to its predecessors. Its parameter count is not publicly disclosed.</li>
</ul></li>
<li>GPT-4o-Mini
<ul>
<li>Summary: Released in May 2024, GPT-4o-Mini is a smaller, faster variant of GPT-4o intended for testing purposes, and its performance is anticipated to be closer to that of GPT-4, but its parameter count is not publicly disclosed.</li>
</ul></li>
</ul></li>
<li>Groq Models
<ul>
<li>Gemma2-9b-it
<ul>
<li>Summary: Gemma2-9b-it is a 9 billion parameter, open-access language model from Google, scheduled for release in June 2024. It is the second generation of the Gemma models.</li>
</ul></li>
<li>Llama-3.1-70b-versatile
<ul>
<li>Summary: Released in April 2024, Llama-3.1-70b-versatile is a 70 billion parameter, open-source language model from Meta, notable for its performance on various benchmarks, including reasoning and coding tasks.</li>
</ul></li>
<li>Llama-3.1-8b-versatile
<ul>
<li>Summary: Released in April 2024, Llama-3.1-8b-versatile is an 8 billion parameter, open-source language model from Meta, designed to be more accessible for developers with limited computational resources.</li>
</ul></li>
<li>Mixtral-8x7b
<ul>
<li>Summary: Released in December 2023, Mixtral-8x7b is a 46.7 billion parameter, open-source language model from Mistral AI, utilizing a sparse mixture-of-experts architecture.</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="analytical-approach" class="level2">
<h2 class="anchored" data-anchor-id="analytical-approach">Analytical Approach</h2>
<p>For our analysis, we build a series of linear regression models, that attempt to forecast the predicted risk of any one entry based on other factors. While this approach isn’t perfect, it gives us a quick and replicable way of building a statistical model for how each language model makes decisions, and attempting to isolate the effect (if any) of any one factor.</p>
<p>We treat every variable as either categorical with a dummy variable or a boolean (for example, our sex variable with be 1 for female, and 0 for male). Again, while this approach is not perfect, it allows us rapid and interpretable analytical approach.</p>
<p><span class="math display">\[
\begin{align}
\text{RiskAssessment} = \beta_0 &amp;+ \beta_1\text{LocationUS} + \beta_2\text{LocationInternational} \\
&amp;+ \beta_3\text{RiskFactor}_\text{out of character} \\
&amp;+ \beta_4\text{Gender}_\text{male} \\
&amp;+ \beta_5\text{AgeGroup}_\text{&gt;25} \\
&amp;+ \beta_6\text{TimeMissing}_\text{&gt;8hrs} \\
&amp;+ \beta_7\text{Ethnicity}_\text{white} + \epsilon
\end{align}
\]</span></p>
<p>We also build an additional bespoke model for human decision makers, to allow us to consider additional variables (whether they are police affiliated, and their location).</p>
<p><span class="math display">\[
\begin{align}
\text{RiskAssessment} = \beta_0 &amp;+ \beta_1\text{IsPoliceOfficer} + \beta_2\text{PoliceFamily} + \beta_3\text{MemberOfPublic} \\
&amp;+ \beta_4\text{LocationUS} + \beta_5\text{LocationInternational} \\
&amp;+ \beta_6\text{RiskFactor}_\text{out of character} \\
&amp;+ \beta_7\text{Gender}_\text{male} \\
&amp;+ \beta_8\text{AgeGroup}_\text{&gt;25} \\
&amp;+ \beta_9\text{TimeMissing}_\text{&gt;8hrs} \\
&amp;+ \beta_{10}\text{Ethnicity}_\text{white} + \epsilon
\end{align}
\]</span></p>
<p>Using these models, we can then examine the coefficients for individual factors to understand their strength, and statistical significance to understand if they have a broadly meaningful impact.</p>
</section>
</section>
<section id="results" class="level1 page-columns page-full">
<h1>Results</h1>
<section id="model-performance" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="model-performance">Model performance</h2>
<p>To obtain a high level view of how the model perceptions of risk compare to human submitted scores, we calculate a few metrics on a model by model basis, treating the human risk submission as “correct” for the given scenario. For each model, we compute the mean error, mean absolute error, variance of error, and root mean square error (RMSE).</p>
<div class="cell" data-execution_count="3">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the CSV file</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> load_data(file_path):</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> pd.read_csv(file_path)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> data</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Process the data to calculate metrics</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_metrics(data):</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Filter out human predictions as the baseline</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    human_predictions <span class="op">=</span> data[data[<span class="st">'model'</span>] <span class="op">==</span> <span class="st">'human'</span>][[<span class="st">'id'</span>, <span class="st">'predicted_risk'</span>]]</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    human_predictions.rename(columns<span class="op">=</span>{<span class="st">'predicted_risk'</span>: <span class="st">'human_risk'</span>}, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Merge human predictions into the main dataset</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    merged_data <span class="op">=</span> data.merge(human_predictions, on<span class="op">=</span><span class="st">'id'</span>, how<span class="op">=</span><span class="st">'left'</span>)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate errors</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    merged_data[<span class="st">'error'</span>] <span class="op">=</span> merged_data[<span class="st">'predicted_risk'</span>] <span class="op">-</span> merged_data[<span class="st">'human_risk'</span>]</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    merged_data[<span class="st">'absolute_error'</span>] <span class="op">=</span> merged_data[<span class="st">'error'</span>].<span class="bu">abs</span>()</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Group by model to calculate metrics</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>    model_metrics <span class="op">=</span> merged_data.groupby(<span class="st">'model'</span>).agg({</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>        <span class="st">'error'</span>: [<span class="st">'mean'</span>, <span class="st">'var'</span>],</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>        <span class="st">'absolute_error'</span>: <span class="st">'mean'</span>,</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>        <span class="st">'predicted_risk'</span>: <span class="kw">lambda</span> x: np.sqrt(np.mean((x <span class="op">-</span> merged_data.loc[x.index, <span class="st">'human_risk'</span>]) <span class="op">**</span> <span class="dv">2</span>))</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>    }).reset_index()</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Rename columns for clarity</span></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>    model_metrics.columns <span class="op">=</span> [<span class="st">'model'</span>, <span class="st">'mean_error'</span>, <span class="st">'variance_error'</span>, <span class="st">'mean_absolute_error'</span>, <span class="st">'rmse'</span>]</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model_metrics</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Main function to process the file and return a dataframe</span></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> main(file_path):</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> load_data(file_path)</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Rename specific models</span></span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>    data[<span class="st">'model'</span>] <span class="op">=</span> data[<span class="st">'model'</span>].replace({</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>        <span class="st">'groq/mixtral-8x7b-32768'</span>: <span class="st">'mixtral-8x7b'</span>,</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>        <span class="st">'groq/llama-3.1-8b-instant'</span>: <span class="st">'llama-3.1-8b'</span></span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate and return metrics as a dataframe</span></span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> calculate_metrics(data)</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>file_path <span class="op">=</span> <span class="st">'data/results.csv'</span></span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>metrics_df <span class="op">=</span> main(file_path)</span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>metrics_df[<span class="st">'model'</span>] <span class="op">=</span> metrics_df[<span class="st">'model'</span>].<span class="bu">str</span>.replace(<span class="st">'groq/'</span>, <span class="st">''</span>)</span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>metrics_df.columns <span class="op">=</span> [<span class="st">'model'</span>, <span class="st">'Mean Error'</span>, <span class="st">'Variance of Error'</span>, <span class="st">'Mean Absolute Error'</span>, <span class="st">'RMSE'</span>]</span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a>metrics_df.drop(<span class="dv">5</span>).set_index(<span class="st">'model'</span>).sort_values(<span class="st">'RMSE'</span>).<span class="bu">round</span>(<span class="dv">3</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div id="tbl-model-performance" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-execution_count="3">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-model-performance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Model error metrics (as compared to human risk scores)
</figcaption>
<div aria-describedby="tbl-model-performance-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output cell-output-display" data-execution_count="3">
<div>


<table class="dataframe do-not-create-environment cell caption-top table table-sm table-striped small" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">Mean Error</th>
<th data-quarto-table-cell-role="th">Variance of Error</th>
<th data-quarto-table-cell-role="th">Mean Absolute Error</th>
<th data-quarto-table-cell-role="th">RMSE</th>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">model</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<th data-quarto-table-cell-role="th">llama-3.1-70b-versatile</th>
<td>-0.030</td>
<td>0.503</td>
<td>0.561</td>
<td>0.710</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">gpt-4o-mini</th>
<td>-0.027</td>
<td>0.572</td>
<td>0.567</td>
<td>0.756</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">gpt-4o</th>
<td>0.346</td>
<td>0.546</td>
<td>0.588</td>
<td>0.816</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">llama-3.1-8b</th>
<td>-0.245</td>
<td>0.793</td>
<td>0.732</td>
<td>0.924</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">gemma2-9b-it</th>
<td>-0.423</td>
<td>0.742</td>
<td>0.780</td>
<td>0.960</td>
</tr>
<tr class="even">
<th data-quarto-table-cell-role="th">gpt-3.5-turbo</th>
<td>0.007</td>
<td>0.966</td>
<td>0.812</td>
<td>0.983</td>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">mixtral-8x7b</th>
<td>-0.698</td>
<td>0.725</td>
<td>0.878</td>
<td>1.101</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</figure>
</div>
</div>
<p>Model by model scores are listed in <a href="#tbl-model-performance" class="quarto-xref">Table&nbsp;1</a>, and are ranked by RMSE, which suggests that the model least that is most closely aligned to human performance is Llama-3.1-70b, with a mean error of 0.561. Conversely, the model least aligned is mixtral, with a mean error of 0.878 (nearly double that of Llama 3.1).</p>
<p>While it is challenging to interpret these results, two conclusions stand out. First, this is quite a large variance in “performance”: the mean absolute error for mixtral is more than 50% larger than that of Llama 70b, despite the fact they are models of broadly similar sizes (though with very different architectures.)</p>
<p>Secondly, we also see variance in the <em>direction</em> of the mean error by model: while gpt-4o performs well on average, it seems to regularly over-estimate risk compared to human evaluators, with a mean error of 0.346, while mixtral seems to under under-estimate it instead, with a mean error of -0.698. Notably, while gpt-3.5 performs relatively poorly (with an RMSE of 0.983), it’s mean error is close to 0, suggesting it’s risk scores reflect human decision makers on average, but suffer from high variance - this is also reflected in the high variance of error.</p>
<p>To explore this variance futher, we provide, for each model, their current score on <a href="https://lmarena.ai/">Chatbot Arena</a>, an “open-source platform for evaluating AI through human preference, developed by researchers at UC Berkeley SkyLab and LMSYS” <span class="citation" data-cites="chiangChatbotArenaOpen2024">(see <a href="#ref-chiangChatbotArenaOpen2024" role="doc-biblioref">Chiang et al. 2024</a>)</span> - these provide a broad metric of how “good” human scorers consider the model to be on general tasks.</p>
<p>We also compare this with the r-squared value of the model by model regression, which will also reflect the consistency of decision making, with models with the highests r-squared exhibiting predictable and consistent decisions. These scores are listed in <a href="#tbl-arena-scores" class="quarto-xref">Table&nbsp;2</a>.</p>
<div id="tbl-arena-scores" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-arena-scores-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2: Model variance, RMSE and Arena score
</figcaption>
<div aria-describedby="tbl-arena-scores-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 26%">
<col style="width: 29%">
<col style="width: 29%">
<col style="width: 14%">
</colgroup>
<thead>
<tr class="header">
<th>Model</th>
<th>R2 (of model regression)</th>
<th>RMSE (compared to human)</th>
<th>Arena Score</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>llama-3.1-70b-versatile</td>
<td>0.634</td>
<td>0.710</td>
<td>1248</td>
</tr>
<tr class="even">
<td>gpt-4o-mini</td>
<td>0.825</td>
<td>0.756</td>
<td>1273</td>
</tr>
<tr class="odd">
<td>gpt-4o</td>
<td>0.796</td>
<td>0.816</td>
<td>1317</td>
</tr>
<tr class="even">
<td>llama-3.1-8b-instant</td>
<td>0.303</td>
<td>0.924</td>
<td>1176</td>
</tr>
<tr class="odd">
<td>gemma2-9b-it</td>
<td>0.276</td>
<td>0.960</td>
<td>1191</td>
</tr>
<tr class="even">
<td>gpt-3.5-turbo</td>
<td>0.662</td>
<td>0.983</td>
<td>1117</td>
</tr>
<tr class="odd">
<td>mixtral-8x7b-32768</td>
<td>0.786</td>
<td>1.101</td>
<td>1114</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>For ease of interpretation, we also visualise these scores in a scatter plot <a href="#fig-model-comparison-arena" class="quarto-xref">Figure&nbsp;1</a>.</p>
<p>On the X axis, we display our regression R-squared value (with models furthest to the right being most consistent), while the Y axis shows our RMSE value (with models nearest to 0 being the closest to human decision makers). Finally, the size of the “bubble” reflects the model score on LM Arena, with larger bubbles indicating answers most preferred by human scorers.</p>
<p>We should expect our “best” models to be at the bottom right of the chart, with a large bubble, indicating highly consistent decisions, that reflect human scores, and are scored highly by humans on general tasks.</p>
<p>Looking at the plot, while we do the models we expect to perform well in that corner (llama-70b, gpt-4o, and 4o-mini are all grouped in this region), where the rest of the models are placed is notable.</p>
<p>Our two smallest models (gemma-9b and llama-8b) are clustered together, indicating similar variance and error, but also have comparatively high LM Arena scores, <strong>indicating that while they might generate satisfying answers to common tasks, they are comparatively poor in the domain of assessing risk.</strong></p>
<p>Our “mid-range” models (gpt-3.5 and mixtral) fall broadly in between, but notably there is a fair bit of difference between the scores and consistency of both models (which will continued to be notable as we dig into model by model differences).</p>
<div id="cell-fig-model-comparison-arena" class="cell page-columns page-full" data-execution_count="4">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Read and prepare the data</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">'data/model_variance.csv'</span>)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate normalized sizes</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>score_min <span class="op">=</span> data[<span class="st">'Arena Score'</span>].<span class="bu">min</span>()</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>score_max <span class="op">=</span> data[<span class="st">'Arena Score'</span>].<span class="bu">max</span>()</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>normalized_sizes <span class="op">=</span> ((data[<span class="st">'Arena Score'</span>] <span class="op">-</span> score_min) <span class="op">/</span> (score_max <span class="op">-</span> score_min) <span class="op">*</span> <span class="dv">800</span>) <span class="op">+</span> <span class="dv">200</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the plot with extra width to accommodate legend</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">6</span>))  <span class="co"># Increased width from 12 to 14</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Create scatter plot</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>scatter <span class="op">=</span> plt.scatter(data[<span class="st">'R2 (of model regression)'</span>], </span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>                     data[<span class="st">'RMSE (compared to human)'</span>],</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>                     s<span class="op">=</span>normalized_sizes,</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>                     alpha<span class="op">=</span><span class="fl">0.6</span>,</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>                     color<span class="op">=</span><span class="st">'blue'</span>,</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>                     marker<span class="op">=</span><span class="st">'o'</span>)</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Add annotations for each point with adjusted offset</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, model <span class="kw">in</span> <span class="bu">enumerate</span>(data[<span class="st">'Model'</span>]):</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>    plt.annotate(model, </span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>                (data[<span class="st">'R2 (of model regression)'</span>].iloc[i], data[<span class="st">'RMSE (compared to human)'</span>].iloc[i]),</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>                xytext<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">10</span>),  <span class="co"># Increased offset</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>                textcoords<span class="op">=</span><span class="st">'offset points'</span>,</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>                fontsize<span class="op">=</span><span class="dv">9</span>,       <span class="co"># Slightly larger font</span></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>                alpha<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Add axis labels and title</span></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'R² (Model Regression)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'RMSE (Compared to Human)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Create legend with actual sizes matching the scatter plot</span></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>reference_scores <span class="op">=</span> [<span class="dv">1100</span>, <span class="dv">1200</span>, <span class="dv">1300</span>]</span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>reference_sizes <span class="op">=</span> ((np.array(reference_scores) <span class="op">-</span> score_min) <span class="op">/</span> (score_max <span class="op">-</span> score_min) <span class="op">*</span> <span class="dv">800</span>) <span class="op">+</span> <span class="dv">200</span></span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>legend_elements <span class="op">=</span> []</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> score, size <span class="kw">in</span> <span class="bu">zip</span>(reference_scores, reference_sizes):</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>    legend_elements.append(</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>        plt.scatter([], [], </span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>                   s<span class="op">=</span>size,</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>                   c<span class="op">=</span><span class="st">'blue'</span>,</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>                   alpha<span class="op">=</span><span class="fl">0.6</span>,</span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>                   marker<span class="op">=</span><span class="st">'o'</span>,</span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>                   label<span class="op">=</span><span class="ss">f'Arena Score: </span><span class="sc">{</span>score<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Add legend with improved spacing</span></span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a>plt.legend(handles<span class="op">=</span>legend_elements,</span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a>          title<span class="op">=</span><span class="st">'Arena Score Reference'</span>,</span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a>          bbox_to_anchor<span class="op">=</span>(<span class="fl">1.05</span>, <span class="fl">0.5</span>),</span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a>          loc<span class="op">=</span><span class="st">'center left'</span>,</span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a>          title_fontsize<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a>          frameon<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a>          edgecolor<span class="op">=</span><span class="st">'black'</span>,</span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a>          fancybox<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a>          shadow<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a>          labelspacing<span class="op">=</span><span class="dv">3</span>,       <span class="co"># Vertical space between entries</span></span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a>          borderpad<span class="op">=</span><span class="dv">1</span>,          <span class="co"># Padding between legend border and entries</span></span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a>          handletextpad<span class="op">=</span><span class="dv">8</span>       <span class="co"># Space between marker and text</span></span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a>          )</span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a><span class="co"># Show the plot</span></span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display page-columns page-full">
<div id="fig-model-comparison-arena" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-model-comparison-arena-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca" class="page-columns page-full">
<img src="analysis_files/figure-html/fig-model-comparison-arena-output-1.png" class="img-fluid figure-img column-page-inset">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-model-comparison-arena-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Scatter plot of model error against humans (RMSE), variance (R2) and arena score
</figcaption>
</figure>
</div>
</div>
</div>
<section id="comparing-regression-models" class="level3">
<h3 class="anchored" data-anchor-id="comparing-regression-models">Comparing regression models</h3>
<p>To compare our models, we will examine the coefficients of each factor (meaning how much, on average, they seem to effect the risk score, attempting to hold other factors constant.) We also generate p-values and error bars at the 95% confidence interval, to examine if the individual factors are significant - p-values are not a perfect tool for this approach, but give us a repeatable rule of thumb we can use for our analysis, allowing us to see if individual factors seem to make a meaningful impact on perceptions of risk. As such, when we refer to significance, this refers to the p&lt;00.5 level, but this should be cautiously interpreted.</p>
<section id="human-specific-factors" class="level4">
<h4 class="anchored" data-anchor-id="human-specific-factors">Human specific factors</h4>
<p>We begin by examining human scorers in isolation in <a href="#tbl-human-regression" class="quarto-xref">Table&nbsp;3</a>, to look at 2 factors which do not apply to our language models:</p>
<div id="tbl-human-regression" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-human-regression-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;3: Regression coefficients for human decision model
</figcaption>
<div aria-describedby="tbl-human-regression-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 18%">
<col style="width: 11%">
<col style="width: 16%">
<col style="width: 5%">
<col style="width: 16%">
<col style="width: 14%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th>Variable</th>
<th>coef</th>
<th>std err</th>
<th>t</th>
<th>P&gt;|t|</th>
<th>[0.025</th>
<th>0.975]</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Intercept</td>
<td>1.5388</td>
<td>0.216</td>
<td>7.139</td>
<td>0.000</td>
<td>1.115</td>
<td>1.962</td>
</tr>
<tr class="even">
<td>is_police_officer</td>
<td>-0.1656</td>
<td>0.189</td>
<td>-0.876</td>
<td>0.382</td>
<td>-0.537</td>
<td>0.206</td>
</tr>
<tr class="odd">
<td>is_police_family</td>
<td>-0.2228</td>
<td>0.195</td>
<td>-1.142</td>
<td>0.254</td>
<td>-0.606</td>
<td>0.161</td>
</tr>
<tr class="even">
<td>is_public</td>
<td>-0.3689</td>
<td>0.195</td>
<td>-1.896</td>
<td>0.058</td>
<td>-0.751</td>
<td>0.013</td>
</tr>
<tr class="odd">
<td>us_based</td>
<td>0.6840</td>
<td>0.309</td>
<td>2.211</td>
<td>0.027</td>
<td>0.076</td>
<td>1.292</td>
</tr>
<tr class="even">
<td>based_elsewhere</td>
<td>0.4883</td>
<td>0.230</td>
<td>2.119</td>
<td>0.035</td>
<td>0.036</td>
<td>0.941</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Each scorer was asked whether they were a police officer, part of the wider policing family, such as retired officers or police staff, or a member of the public (these were each binary variables, so in theory respondents could select all 3). While none are statistically significant, there is a broad trend downwards, with officers likely to perceive high risk than members of the police family, who in turn seem to perceive it higher than the general public.</p>
<p>On location, we do seem to have significant results (though our number of returns is relatively small), which suggest that UK based respondents (the reference category) consistently perceived a lower risk (around 0.5-0.7) than those outside the UK (though there is likely to be heavy overlap between this and the previous category).</p>
</section>
</section>
</section>
<section id="individual-factor-comparisons" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="individual-factor-comparisons">Individual factor comparisons</h2>
<section id="age" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="age">Age</h3>
<div id="cell-fig-coefficients-age" class="cell page-columns page-full" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>coefficient_plots[<span class="st">'Age (25 as reference category)'</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display page-columns page-full" data-execution_count="5">
<div id="fig-coefficients-age" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-coefficients-age-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca" class="page-columns page-full">
<img src="analysis_files/figure-html/fig-coefficients-age-output-1.png" class="img-fluid figure-img column-page-inset">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-coefficients-age-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Regression coefficients by age (25 as reference category)
</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#fig-coefficients-age" class="quarto-xref">Figure&nbsp;2</a> suggests suggests strong age-related patterns in both human and model assessments. Humans show dramatically higher risk assessments for very young ages (5-14) compared to the reference age of 25, with coefficients declining steadily with age, before increasing for our eldest category (with 80 year olds being assessed somewhere between 10 and 14 year olds in terms of risk).</p>
<p>The best models, such as GPT4o, closely mirror this pattern, though notably GPT4o consistently has even higher coefficients. Other models show more varied responses, with Llama models and Gemma showing generally lower coefficients than humans, particularly for young ages. Notably, many models show no increase in risk from 50 to 80 years old, and mixtral actually displays a small (but significant) decrease.</p>
</section>
<section id="sex" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="sex">Sex</h3>
<div id="cell-fig-coefficients-sex" class="cell page-columns page-full" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>coefficient_plots[<span class="st">'Sex (female as reference category)'</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display page-columns page-full" data-execution_count="6">
<div id="fig-coefficients-sex" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-coefficients-sex-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca" class="page-columns page-full">
<img src="analysis_files/figure-html/fig-coefficients-sex-output-1.png" class="img-fluid figure-img column-page-inset">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-coefficients-sex-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Regression coefficients by sex (female as reference category)
</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#fig-coefficients-sex" class="quarto-xref">Figure&nbsp;3</a> suggests shows significant, but relatively small, effects of sex on risk assessment for both humans and models, with humans reducing their risk by about 0.2 for men. Again, we see the highest performing models behaving broadly similarly (with gpt-4o and llama-70b both reducing their risk by around 0.10-0.15), variance amongst smaller models, with mixtral actually seeing a small but significant increase in risk perception for men.</p>
</section>
<section id="time-missing" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="time-missing">Time Missing</h3>
<div id="cell-fig-coefficients-hours-missing" class="cell page-columns page-full" data-execution_count="7">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>coefficient_plots[<span class="st">'Hours missing (8 as reference category)'</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display page-columns page-full" data-execution_count="7">
<div id="fig-coefficients-hours-missing" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-coefficients-hours-missing-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca" class="page-columns page-full">
<img src="analysis_files/figure-html/fig-coefficients-hours-missing-output-1.png" class="img-fluid figure-img column-page-inset">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-coefficients-hours-missing-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Regression coefficients by hours missing (8 as reference category)
</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#fig-coefficients-hours-missing" class="quarto-xref">Figure&nbsp;4</a> is notable because our human risk scorers did <em>not</em> show significant variations in risk assessments based on how long the subject had been reported missing: there is simply too much variance to detect a consistent effect.</p>
<p>That is <em>not</em> the case for our models: gpt-4o and gpt-4o-mini both show increases at the ten and 14 hour marks, while interestingly, llama3.1-8b seems to exhibit a notable decrease.</p>
<p><strong>Notably, nearly all these effects become significantly weaker, or disappear entirely, at the 18 hour mark.</strong> The varying factor in the text of this vignette is the time at which they are being reported missing - at the 18 hour mark, the report is being made at 6AM, and the subject has been missing since midday the previous day - and this seems to have strong, unexpected effects on model behaviour.</p>
</section>
<section id="risk-factors" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="risk-factors">Risk Factors</h3>
<div id="cell-fig-coefficients-risk-factor" class="cell page-columns page-full" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>coefficient_plots[<span class="st">'Risk Factor (out of character as reference category)'</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display page-columns page-full" data-execution_count="8">
<div id="fig-coefficients-risk-factor" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-coefficients-risk-factor-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca" class="page-columns page-full">
<img src="analysis_files/figure-html/fig-coefficients-risk-factor-output-1.png" class="img-fluid figure-img column-page-inset">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-coefficients-risk-factor-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Regression coefficients by risk factor (out of character as reference category
</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#fig-coefficients-hours-missing" class="quarto-xref">Figure&nbsp;4</a> shows that for involvement in crime or being a regular missing person (compared to the missing episode being out of character), humans show negative coefficients, suggesting they assess lower risk for these categories.</p>
<p>The regular missing person risk factor shows broad consistency along our models, with risk decreasing across the board. Involvement in crime however, shows more variance: gpt-3.5 shows a strong increase in risk, while gpt-4o-mini shows a strong decrease instead. This is quite striking variance, and may reflect the lengthier scenarios.</p>
</section>
<section id="ethnicity" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="ethnicity">Ethnicity</h3>
<div id="cell-fig-coefficients-ethnicity" class="cell page-columns page-full" data-execution_count="9">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>coefficient_plots[<span class="st">'Ethnicity (white as reference category)'</span>]</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-display page-columns page-full" data-execution_count="9">
<div id="fig-coefficients-ethnicity" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-coefficients-ethnicity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca" class="page-columns page-full">
<img src="analysis_files/figure-html/fig-coefficients-ethnicity-output-1.png" class="img-fluid figure-img column-page-inset">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-coefficients-ethnicity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Regression coefficients by ethnicity (white as reference category)
</figcaption>
</figure>
</div>
</div>
</div>
<p><a href="#fig-coefficients-ethnicity" class="quarto-xref">Figure&nbsp;6</a> shows that ethnicity made no significant difference to the risk assessment of human assessors - they show no apparent racial bias.</p>
<p><strong>However, nearly every single model does: while the differences are small, they all appear significant for at least one ethnicity.</strong> Gpt-4o-mini and llama-8b both show increased risk scores of at least 0.1 for subjects that are not white, and most models increase their risk scores for Black and mixed-race subjects.</p>
<p>Notably, gpt-4o and mixtral both show no bias on Asian or Black subjects, but do for mixed-race.</p>
</section>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<p>In this analysis, we’ve compared responses from humans and large language models, using statistical models to measure where they agree, where they disagree, and where they exhibit bias.</p>
<p>At a high level, the results are promising: the most highly performing, “flagship” models, seem to perceive risk and threat in the context of missing people in ways that are similar to human scorers. Scored on a scale from 0 to 4 (where 0 is very low risk and 4 is high risk), a mean error of well under 1 suggest they would lead to outcomes broadly similar to humans, if deployed in a policing context.</p>
<p>For certain risk-factors, such as age, these models also vary their perceptions of risk in ways that are broadly reasonable, and similar to human decision makers (for example, perceiving the very young, or very old, as being most at risk.) We also noted that, for at least one risk factor (the number of hours since the suspect had gone missing), some language models identified a clear risk to a subject, where human decision makers did not - this suggests models could be used as safeguards around inaccurate decision making.</p>
<p>However, we also identify some causes for concern. Performance varied significantly across models, even for models of similar size, and some models that are generally perceived to do well on general tasks, did not perform as well in their perception of policing risk. We also saw broad variance with how models evaluated the importance of risk factors: models that might perform well overall might still display unexpected behaviours in certain contexts.</p>
<p>In some areas, these behaviours highlighted biases that are likely to be problematic for policing - most notably, when looking at race. <strong>While human decision makers exhibited no statistically significant racial bias in their perception of risk, each and every model we evaluated did, for at least one ethnicity category.</strong></p>
<section id="lessons-for-policy-and-practice" class="level3">
<h3 class="anchored" data-anchor-id="lessons-for-policy-and-practice">Lessons for policy and practice</h3>
<p>While the findings of this research should be caveated, it does suggest lessons for the application of LLMs in the context of policing, crime and justice, and other domains where perceived risk and threat may be relevant.</p>
<p>Not all models are equal, but most importantly, <strong>models which perform best in generalist contexts might not be best suited to this context.</strong> Smaller models can be especially problematic, and while these might lead to savings through reduced costs, are likely to have significant other downsides due to their variabilities and biases.</p>
<p>When Daniel Kahneman examined variance in decision making in “Thinking, fast and slow” <span class="citation" data-cites="kahnemanThinkingFastSlow2013">(<a href="#ref-kahnemanThinkingFastSlow2013" role="doc-biblioref">Kahneman 2013</a>)</span>, he recommended that companies or agencies where decision making consistency might be critical (such as insurance agencies or judges) undertake a “noise audit” to examine existing variance in their processes. Those considering the application of large language models to policing domains should aim to run a “virtual audit” on historical data, examining a range of language models to examine how they perform on the required task.</p>
<p>This audit should examine not just variance on the given task, but where variance does exist, does it behave in ways we would expect, and how does it compare to existing human processes. For example, our analysis found while some models treated regularly going missing as a factor that decreased risk, other models saw it as an aggravating factor - you should reassure yourself that any language model being considered for deployment into an operational context at least behaves in line with training and procedures you expect human decision makers to follow.</p>
<p>Finally, any audit should pay special care biases around race, as our analysis suggest the majority of models attribute some bias in this domain, which does not reflect human decision making. Given the potentially catastrophic implications of algorithmic bias for embedding structural concerns, not to mention legal implications, special care should be paid to this category, as well as other protected characteristics.</p>



</section>
</section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-adamsNoMansHand2024" class="csl-entry" role="listitem">
Adams, Ian T., Matt Barter, Kyle McLean, Hunter Boehme, and Irick A. Geary. 2024. <span>“No <span>Man</span>’s <span>Hand</span>: <span>Artificial Intelligence Does Not Improve Police Report Writing Speed</span>.”</span> <em>CrimRxiv</em>. <a href="https://doi.org/10.21428/cb6ab371.4a6d42e9">https://doi.org/10.21428/cb6ab371.4a6d42e9</a>.
</div>
<div id="ref-brynjolfssonGenerativeAIWork2023" class="csl-entry" role="listitem">
Brynjolfsson, Erik, Danielle Li, and Lindsey R. Raymond. 2023. <span>“Generative <span>AI</span> at <span>Work</span>.”</span> Working {{Paper}}. Working <span>Paper Series</span>. National Bureau of Economic Research. <a href="https://doi.org/10.3386/w31161">https://doi.org/10.3386/w31161</a>.
</div>
<div id="ref-chanConversationalAIPowered2024" class="csl-entry" role="listitem">
Chan, Samantha, Pat Pataranutaporn, Aditya Suri, Wazeer Zulfikar, Pattie Maes, and Elizabeth F. Loftus. 2024. <span>“Conversational <span>AI Powered</span> by <span>Large Language Models Amplifies False Memories</span> in <span>Witness Interviews</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2408.04681">https://doi.org/10.48550/arXiv.2408.04681</a>.
</div>
<div id="ref-chiangChatbotArenaOpen2024" class="csl-entry" role="listitem">
Chiang, Wei-Lin, Lianmin Zheng, Ying Sheng, Anastasios Nikolas Angelopoulos, Tianle Li, Dacheng Li, Hao Zhang, et al. 2024. <span>“Chatbot <span>Arena</span>: <span>An Open Platform</span> for <span>Evaluating LLMs</span> by <span>Human Preference</span>.”</span> arXiv. <a href="https://doi.org/10.48550/arXiv.2403.04132">https://doi.org/10.48550/arXiv.2403.04132</a>.
</div>
<div id="ref-fergusonGenerativeSuspicionRisks2024" class="csl-entry" role="listitem">
Ferguson, Andrew Guthrie. 2024. <span>“Generative <span>Suspicion</span> and the <span>Risks</span> of <span>AI-Assisted Police Reports</span>.”</span> {{SSRN Scholarly Paper}}. Rochester, NY: Social Science Research Network.
</div>
<div id="ref-hobsonArtificialFairnessTrust2023" class="csl-entry" role="listitem">
Hobson, Zoë, Julia A. Yesberg, Ben Bradford, and Jonathan Jackson. 2023. <span>“Artificial Fairness? <span>Trust</span> in Algorithmic Police Decision-Making.”</span> <em>Journal of Experimental Criminology</em> 19 (1): 165–89. <a href="https://doi.org/10.1007/s11292-021-09484-9">https://doi.org/10.1007/s11292-021-09484-9</a>.
</div>
<div id="ref-kahnemanThinkingFastSlow2013" class="csl-entry" role="listitem">
Kahneman, Daniel. 2013. <em>Thinking, Fast and Slow</em>. First paperback edition. New York: <span>Farrar, Straus and Giroux</span>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>https://www.axon.com/products/draft-one<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>https://policinginsight.com/feature/advertisement/fighting-the-bad-and-finding-the-good-in-generative-ai/<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/andreasthinks\.me");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>