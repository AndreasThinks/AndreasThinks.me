@misc{adamsNoMansHand2024,
  title = {No {{Man}}'s {{Hand}}: {{Artificial Intelligence Does Not Improve Police Report Writing Speed}}},
  shorttitle = {No {{Man}}'s {{Hand}}},
  author = {Adams, Ian T. and Barter, Matt and McLean, Kyle and Boehme, Hunter and Geary, Irick A.},
  year = {2024},
  month = sep,
  journal = {CrimRxiv},
  doi = {10.21428/cb6ab371.4a6d42e9},
  urldate = {2024-12-20},
  abstract = {Objectives: This study examines the potential of artificial intelligence (AI) to reduce the time police officers spend writing reports, a task that consumes a significant portion of their workday.Methods: In a pre-registered randomized controlled trial, we test this claim within the patrol division of a medium-sized police department (n=85), at the individual report level (n=755). Analyses utilize mixed-effects regression accounting for the nested structure of report-writing.Results: AI assistance did not significantly affect the duration of writing police reports. Alternative specifications beyond those specified in the pre-registration, including a difference-in-differences approach observing report duration over a full year (n=6,084), confirms the null findings are robust.Conclusions: Our findings contradict marketing expectations for the effect of this technology, suggesting no time-savings in report-writing can be expected when using AI-assisted report-writing. Several other potential effects remain possible and untested.},
  langid = {english},
  file = {C:\Users\andre\Zotero\storage\FH5NXEGZ\Adams et al. - 2024 - No Manâ€™s Hand Artificial Intelligence Does Not Improve Police Report Writing Speed.pdf}
}

@misc{brynjolfssonGenerativeAIWork2023,
  type = {Working {{Paper}}},
  title = {Generative {{AI}} at {{Work}}},
  author = {Brynjolfsson, Erik and Li, Danielle and Raymond, Lindsey R.},
  year = {2023},
  month = apr,
  series = {Working {{Paper Series}}},
  number = {31161},
  eprint = {31161},
  publisher = {National Bureau of Economic Research},
  doi = {10.3386/w31161},
  urldate = {2024-12-20},
  abstract = {New AI tools have the potential to change the way workers perform and learn, but little is known about their impacts on the job. In this paper, we study the staggered introduction of a generative AI-based conversational assistant using data from 5,179 customer support agents. Access to the tool increases productivity, as measured by issues resolved per hour, by 14\% on average, including a 34\% improvement for novice and low-skilled workers but with minimal impact on experienced and highly skilled workers. We provide suggestive evidence that the AI model disseminates the best practices of more able workers and helps newer workers move down the experience curve. In addition, we find that AI assistance improves customer sentiment, increases employee retention, and may lead to worker learning. Our results suggest that access to generative AI can increase productivity, with large heterogeneity in effects across workers.},
  archiveprefix = {National Bureau of Economic Research},
  file = {C:\Users\andre\Zotero\storage\Z4QRUV3L\Brynjolfsson et al. - 2023 - Generative AI at Work.pdf}
}

@misc{chanConversationalAIPowered2024,
  title = {Conversational {{AI Powered}} by {{Large Language Models Amplifies False Memories}} in {{Witness Interviews}}},
  author = {Chan, Samantha and Pataranutaporn, Pat and Suri, Aditya and Zulfikar, Wazeer and Maes, Pattie and Loftus, Elizabeth F.},
  year = {2024},
  month = aug,
  number = {arXiv:2408.04681},
  eprint = {2408.04681},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2408.04681},
  urldate = {2024-12-20},
  abstract = {This study examines the impact of AI on human false memories --- recollections of events that did not occur or deviate from actual occurrences. It explores false memory induction through suggestive questioning in Human-AI interactions, simulating crime witness interviews. Four conditions were tested: control, survey-based, pre-scripted chatbot, and generative chatbot using a large language model (LLM). Participants (N=200) watched a crime video, then interacted with their assigned AI interviewer or survey, answering questions including five misleading ones. False memories were assessed immediately and after one week. Results show the generative chatbot condition significantly increased false memory formation, inducing over 3 times more immediate false memories than the control and 1.7 times more than the survey method. 36.4\% of users' responses to the generative chatbot were misled through the interaction. After one week, the number of false memories induced by generative chatbots remained constant. However, confidence in these false memories remained higher than the control after one week. Moderating factors were explored: users who were less familiar with chatbots but more familiar with AI technology, and more interested in crime investigations, were more susceptible to false memories. These findings highlight the potential risks of using advanced AI in sensitive contexts, like police interviews, emphasizing the need for ethical considerations.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computers and Society,Computer Science - Human-Computer Interaction},
  file = {C:\Users\andre\Zotero\storage\KNPKESTW\Chan et al. - 2024 - Conversational AI Powered by Large Language Models Amplifies False Memories in Witness Interviews.pdf}
}

@misc{chiangChatbotArenaOpen2024,
  title = {Chatbot {{Arena}}: {{An Open Platform}} for {{Evaluating LLMs}} by {{Human Preference}}},
  shorttitle = {Chatbot {{Arena}}},
  author = {Chiang, Wei-Lin and Zheng, Lianmin and Sheng, Ying and Angelopoulos, Anastasios Nikolas and Li, Tianle and Li, Dacheng and Zhang, Hao and Zhu, Banghua and Jordan, Michael and Gonzalez, Joseph E. and Stoica, Ion},
  year = {2024},
  month = mar,
  number = {arXiv:2403.04132},
  eprint = {2403.04132},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2403.04132},
  urldate = {2025-01-03},
  abstract = {Large Language Models (LLMs) have unlocked new capabilities and applications; however, evaluating the alignment with human preferences still poses significant challenges. To address this issue, we introduce Chatbot Arena, an open platform for evaluating LLMs based on human preferences. Our methodology employs a pairwise comparison approach and leverages input from a diverse user base through crowdsourcing. The platform has been operational for several months, amassing over 240K votes. This paper describes the platform, analyzes the data we have collected so far, and explains the tried-and-true statistical methods we are using for efficient and accurate evaluation and ranking of models. We confirm that the crowdsourced questions are sufficiently diverse and discriminating and that the crowdsourced human votes are in good agreement with those of expert raters. These analyses collectively establish a robust foundation for the credibility of Chatbot Arena. Because of its unique value and openness, Chatbot Arena has emerged as one of the most referenced LLM leaderboards, widely cited by leading LLM developers and companies. Our demo is publicly available at {\textbackslash}url\{https://chat.lmsys.org\}.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\andre\\Zotero\\storage\\Q2N26B3R\\Chiang et al. - 2024 - Chatbot Arena An Open Platform for Evaluating LLMs by Human Preference.pdf;C\:\\Users\\andre\\Zotero\\storage\\K8CIXNQB\\2403.html}
}

@misc{fergusonGenerativeSuspicionRisks2024,
  type = {{{SSRN Scholarly Paper}}},
  title = {Generative {{Suspicion}} and the {{Risks}} of {{AI-Assisted Police Reports}}},
  author = {Ferguson, Andrew Guthrie},
  year = {2024},
  month = jul,
  number = {4897632},
  eprint = {4897632},
  publisher = {Social Science Research Network},
  address = {Rochester, NY},
  urldate = {2024-12-20},
  abstract = {{$<$}p{$>$}Police reports play a central role in the criminal justice system. Many times, police reports exist as the only official memorialization of what happen},
  archiveprefix = {Social Science Research Network},
  langid = {english},
  keywords = {Andrew Guthrie Ferguson,Generative Suspicion and the Risks of AI-Assisted Police Reports,SSRN},
  file = {C:\Users\andre\Zotero\storage\AU57CTDH\Ferguson - 2024 - Generative Suspicion and the Risks of AI-Assisted Police Reports.pdf}
}

@misc{ngDidAIWrite2024,
  title = {Did an {{AI}} Write up Your Arrest? {{Hard}} to Know},
  shorttitle = {Did an {{AI}} Write up Your Arrest?},
  author = {Ng, Alfred},
  year = {2024},
  month = dec,
  journal = {POLITICO},
  urldate = {2024-12-20},
  howpublished = {https://www.politico.com/newsletters/digital-future-daily/2024/09/04/axon-ai-police-reports-00177331},
  langid = {english},
  file = {C:\Users\andre\Zotero\storage\HNKMQMR5\axon-ai-police-reports-00177331.html}
}

@misc{PoliceOfficersAre2024,
  title = {Police Officers Are Starting to Use {{AI}} Chatbots to Write Crime Reports. {{Will}} They Hold up in Court?},
  year = {2024},
  month = aug,
  journal = {AP News},
  urldate = {2024-12-20},
  abstract = {Pulling from the sounds of a body camera, an AI tool based on the same technology as ChatGPT can churn out a draft in seconds.},
  chapter = {Business},
  howpublished = {https://apnews.com/article/ai-writes-police-reports-axon-body-cameras-chatgpt-a24d1502b53faae4be0dac069243f418},
  langid = {english},
  file = {C:\Users\andre\Zotero\storage\7H88EHYW\ai-writes-police-reports-axon-body-cameras-chatgpt-a24d1502b53faae4be0dac069243f418.html}
}
