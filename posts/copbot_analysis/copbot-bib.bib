@misc{adamsNoMansHand2024,
  title = {No {{Man}}'s {{Hand}}: {{Artificial Intelligence Does Not Improve Police Report Writing Speed}}},
  shorttitle = {No {{Man}}'s {{Hand}}},
  author = {Adams, Ian T. and Barter, Matt and McLean, Kyle and Boehme, Hunter and Geary, Irick A.},
  year = {2024},
  month = sep,
  journal = {CrimRxiv},
  doi = {10.21428/cb6ab371.4a6d42e9},
  urldate = {2024-12-20},
  abstract = {Objectives: This study examines the potential of artificial intelligence (AI) to reduce the time police officers spend writing reports, a task that consumes a significant portion of their workday.Methods: In a pre-registered randomized controlled trial, we test this claim within the patrol division of a medium-sized police department (n=85), at the individual report level (n=755). Analyses utilize mixed-effects regression accounting for the nested structure of report-writing.Results: AI assistance did not significantly affect the duration of writing police reports. Alternative specifications beyond those specified in the pre-registration, including a difference-in-differences approach observing report duration over a full year (n=6,084), confirms the null findings are robust.Conclusions: Our findings contradict marketing expectations for the effect of this technology, suggesting no time-savings in report-writing can be expected when using AI-assisted report-writing. Several other potential effects remain possible and untested.},
  langid = {english},
  file = {C:\Users\andre\Zotero\storage\FH5NXEGZ\Adams et al. - 2024 - No Manâ€™s Hand Artificial Intelligence Does Not Improve Police Report Writing Speed.pdf}
}

@techreport{babutaDataAnalyticsAlgorithmic2024,
  title = {Data {{Analytics}} and {{Algorithmic Bias}} in {{Policing}}},
  author = {Babuta, Alexander and Oswald, Marion},
  year = {2024},
  month = dec,
  institution = {Royal United Services Institute},
  urldate = {2025-01-03},
  abstract = {This paper summarises the use of analytics and algorithms for policing within England and Wales, and explores different types of bias that can arise during the product lifecycle.},
  langid = {english},
  file = {C:\Users\andre\Zotero\storage\KRRN33L7\data-analytics-and-algorithmic-bias-policing.html}
}

@misc{barocasBigDatasDisparate2016,
  type = {{{SSRN Scholarly Paper}}},
  title = {Big {{Data}}'s {{Disparate Impact}}},
  author = {Barocas, Solon and Selbst, Andrew D.},
  year = {2016},
  number = {2477899},
  eprint = {2477899},
  publisher = {Social Science Research Network},
  address = {Rochester, NY},
  doi = {10.2139/ssrn.2477899},
  urldate = {2025-01-03},
  abstract = {Advocates of algorithmic techniques like data mining argue that these techniques eliminate human biases from the decision-making process. But an algorithm is only as good as the data it works with. Data is frequently imperfect in ways that allow these algorithms to inherit the prejudices of prior decision makers. In other cases, data may simply reflect the widespread biases that persist in society at large. In still others, data mining can discover surprisingly useful regularities that are really just preexisting patterns of exclusion and inequality. Unthinking reliance on data mining can deny historically disadvantaged and vulnerable groups full participation in society. Worse still, because the resulting discrimination is almost always an unintentional emergent property of the algorithm's use rather than a conscious choice by its programmers, it can be unusually hard to identify the source of the problem or to explain it to a court.},
  archiveprefix = {Social Science Research Network},
  langid = {english},
  keywords = {algorithms,big data,civil rights,data mining,discrimination,disparate impact,disparate treatment,employment discrimination,inequality,procedural fairness,substantive fairness,Title VII},
  file = {C:\Users\andre\Zotero\storage\956T44GP\Barocas and Selbst - 2016 - Big Data's Disparate Impact.pdf}
}

@misc{brynjolfssonGenerativeAIWork2023,
  type = {Working {{Paper}}},
  title = {Generative {{AI}} at {{Work}}},
  author = {Brynjolfsson, Erik and Li, Danielle and Raymond, Lindsey R.},
  year = {2023},
  month = apr,
  series = {Working {{Paper Series}}},
  number = {31161},
  eprint = {31161},
  publisher = {National Bureau of Economic Research},
  doi = {10.3386/w31161},
  urldate = {2024-12-20},
  abstract = {New AI tools have the potential to change the way workers perform and learn, but little is known about their impacts on the job. In this paper, we study the staggered introduction of a generative AI-based conversational assistant using data from 5,179 customer support agents. Access to the tool increases productivity, as measured by issues resolved per hour, by 14\% on average, including a 34\% improvement for novice and low-skilled workers but with minimal impact on experienced and highly skilled workers. We provide suggestive evidence that the AI model disseminates the best practices of more able workers and helps newer workers move down the experience curve. In addition, we find that AI assistance improves customer sentiment, increases employee retention, and may lead to worker learning. Our results suggest that access to generative AI can increase productivity, with large heterogeneity in effects across workers.},
  archiveprefix = {National Bureau of Economic Research},
  file = {C:\Users\andre\Zotero\storage\Z4QRUV3L\Brynjolfsson et al. - 2023 - Generative AI at Work.pdf}
}

@misc{chanConversationalAIPowered2024,
  title = {Conversational {{AI Powered}} by {{Large Language Models Amplifies False Memories}} in {{Witness Interviews}}},
  author = {Chan, Samantha and Pataranutaporn, Pat and Suri, Aditya and Zulfikar, Wazeer and Maes, Pattie and Loftus, Elizabeth F.},
  year = {2024},
  month = aug,
  number = {arXiv:2408.04681},
  eprint = {2408.04681},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2408.04681},
  urldate = {2024-12-20},
  abstract = {This study examines the impact of AI on human false memories --- recollections of events that did not occur or deviate from actual occurrences. It explores false memory induction through suggestive questioning in Human-AI interactions, simulating crime witness interviews. Four conditions were tested: control, survey-based, pre-scripted chatbot, and generative chatbot using a large language model (LLM). Participants (N=200) watched a crime video, then interacted with their assigned AI interviewer or survey, answering questions including five misleading ones. False memories were assessed immediately and after one week. Results show the generative chatbot condition significantly increased false memory formation, inducing over 3 times more immediate false memories than the control and 1.7 times more than the survey method. 36.4\% of users' responses to the generative chatbot were misled through the interaction. After one week, the number of false memories induced by generative chatbots remained constant. However, confidence in these false memories remained higher than the control after one week. Moderating factors were explored: users who were less familiar with chatbots but more familiar with AI technology, and more interested in crime investigations, were more susceptible to false memories. These findings highlight the potential risks of using advanced AI in sensitive contexts, like police interviews, emphasizing the need for ethical considerations.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computers and Society,Computer Science - Human-Computer Interaction},
  file = {C:\Users\andre\Zotero\storage\KNPKESTW\Chan et al. - 2024 - Conversational AI Powered by Large Language Models Amplifies False Memories in Witness Interviews.pdf}
}

@misc{chiangChatbotArenaOpen2024,
  title = {Chatbot {{Arena}}: {{An Open Platform}} for {{Evaluating LLMs}} by {{Human Preference}}},
  shorttitle = {Chatbot {{Arena}}},
  author = {Chiang, Wei-Lin and Zheng, Lianmin and Sheng, Ying and Angelopoulos, Anastasios Nikolas and Li, Tianle and Li, Dacheng and Zhang, Hao and Zhu, Banghua and Jordan, Michael and Gonzalez, Joseph E. and Stoica, Ion},
  year = {2024},
  month = mar,
  number = {arXiv:2403.04132},
  eprint = {2403.04132},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2403.04132},
  urldate = {2025-01-03},
  abstract = {Large Language Models (LLMs) have unlocked new capabilities and applications; however, evaluating the alignment with human preferences still poses significant challenges. To address this issue, we introduce Chatbot Arena, an open platform for evaluating LLMs based on human preferences. Our methodology employs a pairwise comparison approach and leverages input from a diverse user base through crowdsourcing. The platform has been operational for several months, amassing over 240K votes. This paper describes the platform, analyzes the data we have collected so far, and explains the tried-and-true statistical methods we are using for efficient and accurate evaluation and ranking of models. We confirm that the crowdsourced questions are sufficiently diverse and discriminating and that the crowdsourced human votes are in good agreement with those of expert raters. These analyses collectively establish a robust foundation for the credibility of Chatbot Arena. Because of its unique value and openness, Chatbot Arena has emerged as one of the most referenced LLM leaderboards, widely cited by leading LLM developers and companies. Our demo is publicly available at {\textbackslash}url\{https://chat.lmsys.org\}.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\andre\\Zotero\\storage\\Q2N26B3R\\Chiang et al. - 2024 - Chatbot Arena An Open Platform for Evaluating LLMs by Human Preference.pdf;C\:\\Users\\andre\\Zotero\\storage\\K8CIXNQB\\2403.html}
}

@misc{fergusonGenerativeSuspicionRisks2024,
  type = {{{SSRN Scholarly Paper}}},
  title = {Generative {{Suspicion}} and the {{Risks}} of {{AI-Assisted Police Reports}}},
  author = {Ferguson, Andrew Guthrie},
  year = {2024},
  month = jul,
  number = {4897632},
  eprint = {4897632},
  publisher = {Social Science Research Network},
  address = {Rochester, NY},
  urldate = {2024-12-20},
  abstract = {{$<$}p{$>$}Police reports play a central role in the criminal justice system. Many times, police reports exist as the only official memorialization of what happen},
  archiveprefix = {Social Science Research Network},
  langid = {english},
  keywords = {Andrew Guthrie Ferguson,Generative Suspicion and the Risks of AI-Assisted Police Reports,SSRN},
  file = {C:\Users\andre\Zotero\storage\AU57CTDH\Ferguson - 2024 - Generative Suspicion and the Risks of AI-Assisted Police Reports.pdf}
}

@article{hobsonArtificialFairnessTrust2023,
  title = {Artificial Fairness? {{Trust}} in Algorithmic Police Decision-Making},
  shorttitle = {Artificial Fairness?},
  author = {Hobson, Zo{\"e} and Yesberg, Julia A. and Bradford, Ben and Jackson, Jonathan},
  year = {2023},
  month = mar,
  journal = {Journal of Experimental Criminology},
  volume = {19},
  number = {1},
  pages = {165--189},
  issn = {1572-8315},
  doi = {10.1007/s11292-021-09484-9},
  urldate = {2025-01-03},
  abstract = {Test whether (1) people view a policing decision made by an algorithm as more or less trustworthy than when an officer makes the same decision; (2) people who are presented with a specific instance of algorithmic policing have greater or lesser support for the general use of algorithmic policing in general; and (3) people use trust as a heuristic through which to make sense of an unfamiliar technology like algorithmic policing.},
  langid = {english},
  keywords = {Algorithms,Artificial Intelligence,Fairness,Police decision-making,Technology,Trust},
  file = {C:\Users\andre\Zotero\storage\GL856P3I\Hobson et al. - 2023 - Artificial fairness Trust in algorithmic police decision-making.pdf}
}

@book{kahnemanThinkingFastSlow2013,
  title = {Thinking, Fast and Slow},
  author = {Kahneman, Daniel},
  year = {2013},
  edition = {First paperback edition},
  publisher = {{Farrar, Straus and Giroux}},
  address = {New York},
  abstract = {In this work the author, a recipient of the Nobel Prize in Economic Sciences for his seminal work in psychology that challenged the rational model of judgment and decision making, has brought together his many years of research and thinking in one book. He explains the two systems that drive the way we think. System 1 is fast, intuitive, and emotional; System 2 is slower, more deliberative, and more logical. He exposes the extraordinary capabilities, and also the faults and biases, of fast thinking, and reveals the pervasive influence of intuitive impressions on our thoughts and behavior. He reveals where we can and cannot trust our intuitions and how we can tap into the benefits of slow thinking. He offers practical and enlightening insights into how choices are made in both our business and our personal lives, and how we can use different techniques to guard against the mental glitches that often get us into trouble. This author's work has transformed cognitive psychology and launched the new fields of behavioral economics and happiness studies. In this book, he takes us on a tour of the mind and explains the two systems that drive the way we think and the way we make choices},
  isbn = {978-0-374-53355-7},
  langid = {english},
  keywords = {Besliskunde,decision making,Decision making,Decision Making,Entscheidungsfindung,intuition,Intuition,Livres de croissance personnelle,Pensee,Prise de decision,Psychology,Reasoning,Schlussfolgern,Self-help publications,thinking,Thinking,Thought and thinking},
  annotation = {OCLC: 834531418}
}

@misc{ngDidAIWrite2024,
  title = {Did an {{AI}} Write up Your Arrest? {{Hard}} to Know},
  shorttitle = {Did an {{AI}} Write up Your Arrest?},
  author = {Ng, Alfred},
  year = {2024},
  month = dec,
  journal = {POLITICO},
  urldate = {2024-12-20},
  howpublished = {https://www.politico.com/newsletters/digital-future-daily/2024/09/04/axon-ai-police-reports-00177331},
  langid = {english},
  file = {C:\Users\andre\Zotero\storage\HNKMQMR5\axon-ai-police-reports-00177331.html}
}
